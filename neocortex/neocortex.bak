#!/usr/bin/python

import Pyro4
import syslog
import signal
import os
import imp
from multiprocessing import Process, Value
import MySQLdb as mysql
import sys
import requests
import json
import time

## for vmware
from pyVmomi import vim
from pyVim.connect import SmartConnect, Disconnect

CONFIG_FILE = '/data/cortex/cortex.conf'
Pyro4.config.SERVERTYPE = "multiplex"
Pyro4.config.SOCK_REUSE = True

class NotFoundError(Exception):
	"""Exception to represent a condition where something asked for is not found"""

class DisabledError(Exception):
	"""Exception to represent a condition where something has been disabled"""

class InfobloxError(Exception):
	"""Exception to represent a fault when interacting with Infoblox"""

class NeoCortexLib(object):
	"""Library functions used in both neocortex itself and the neocortex tasks, hence a seperate object"""

	OS_TYPE_BY_ID   = {0: "None", 1: "Linux", 2: "Windows" }
	OS_TYPE_BY_NAME = {"None": 0, "Linux": 1, "Windows": 2}
	SYSTEM_TYPE_BY_ID = {0: "System", 1: "Legacy", 2: "Other"}
	SYSTEM_TYPE_BY_NAME = {"System": 0, "Legacy": 1, "Other": 2}

	def __init__(self, db, config):
		self.db = db
		self.config = config

	################################################################################

	def allocate_name(self, class_name, comment, username, num=1):
		"""Allocates 'num' systems, of type 'class_name' each with the given
		comment. Returns a dictionary with mappings between each new name
		and the corresponding row ID in the database table."""

		# dictionary of new systems
		new_systems = {}

		# Get a cursor to the database
		cur = self.db.cursor(mysql.cursors.DictCursor)

		# The following MySQL code is a bit complicated but as an explanation:
		#  * The classes table contains the number of the next system in each
		#    class to allocate.
		#  * To prevent race conditions when allocating (and thus so two
		#    systems don't get allocated with the same number) we lock the 
		#    tables we want to view/modify during this function.
		#  * This prevents other simultanteously running calls to this function
		#    from allocating a name temporarily (the call to LOCK TABLE will
		#    block/hang until the tables become unlocked again).
		#  * Once a lock is aquired, we get the next number to allocate from
		#    the classes table, update that table with the next new number,
		#    based on how many names we're simultaneously allocating, and then
		#    create the systems in the systems table.
		#  * This is all commited as one transaction so either this all happens
		#    or none of it happens (i.e. in case of an error)
		#  * In all scenarios, we end by unlocking the table so other calls to
		#    this function can carry on.

		## 1. Lock the table to prevent other requests issuing names whilst we are
		cur.execute('LOCK TABLE `classes` WRITE, `systems` WRITE; ')

		# 2a. Get the class (along with the next nubmer to allocate)
		try:
			cur.execute("SELECT * FROM `classes` WHERE `name` = %s",(class_name))
			class_data = cur.fetchone()
		except Exception as ex:
			cur.execute('UNLOCK TABLES;')
			raise NotFoundError

		# 2b. Ensure the class was found and that it is not disabled
		if class_data == None:
			cur.execute('UNLOCK TABLES;')
			raise NotFoundError
		elif int(class_data['disabled']) == 1:
			cur.execute('UNLOCK TABLES;')
			raise DisabledError

		try:
			## 3. Increment the number by the number we're simultaneously allocating
			cur.execute("UPDATE `classes` SET `lastid` = %s WHERE `name` = %s", (int(class_data['lastid']) + int(num), class_name))

			## 4. Create the appropriate number of servers
			for i in xrange(1, num+1):
				new_number = int(class_data['lastid']) + i
				new_name   = self.pad_system_name(class_name, new_number, class_data['digits'])

				cur.execute("INSERT INTO `systems` (`type`, `class`, `number`, `name`, `allocation_date`, `allocation_who`, `allocation_comment`) VALUES (%s, %s, %s, %s, NOW(), %s, %s)",
					(self.SYSTEM_TYPE_BY_NAME['System'], class_name, new_number, new_name, username, comment))

				# store a record of the new system so we can give this back to the browser in a minute
				new_systems[new_name] = cur.lastrowid

			## 5. All names are now created and the table incremented. Time to commit.
			self.db.commit()
		except Exception as ex:
			cur.execute('UNLOCK TABLES;')
			raise ex

		## 6. Finally, unlock the tables so others can allocate
		cur.execute('UNLOCK TABLES;')

		return new_systems

	################################################################################

	def pad_system_name(self, prefix, number, digits):
		"""Takes a class name ('prefix') a system number, and the number of
		digits that class should have in its name and formats a string to that
		specification. For example, if prefix is 'test', number is '12' and
		'digits' is 5, then this returns 'test00012'"""

		return ("%s%0" + str(int(digits)) + "d") % (prefix, number)	

	################################################################################

	def infoblox_create_host(self, name, subnet):
		payload = {'name': name, "ipv4addrs": [{"ipv4addr":"func:nextavailableip:" + subnet}],}
		r = requests.post("https://" + self.config['INFOBLOX_HOST'] + "/wapi/v2.0/record:host", data=json.dumps(payload), auth=(self.config['INFOBLOX_USER'], self.config['INFOBLOX_PASS']))

		if r.status_code == 201:
			objectid = str(r.json())
			r = requests.get("https://" + self.config['INFOBLOX_HOST'] + "/wapi/v2.0/" + objectid, auth=(self.config['INFOBLOX_USER'], self.config['INFOBLOX_PASS']))
	
			if r.status_code == 200:
				response = r.json()

				try:
					return response['ipv4addrs'][0]['ipv4addr']
				except Exception as ex:
					raise InfobloxError("Malformed JSON response from Infoblox API")
			else:
				raise InfobloxError("Error returned from Infoblox API. Code " + str(r.status_code) + ": " + r.text)
		else:
			raise InfobloxError("Error returned from Infoblox API. Code " + str(r.status_code) + ": " + r.text)

	def vmware_get_obj(self, content, vimtype, name):
		"""
		Return an object by name, if name is None the
		first found object is returned
		"""
		obj = None
		container = content.viewManager.CreateContainerView(
		content.rootFolder, vimtype, True)
		for c in container.view:
			if name:
				if c.name == name:
					obj = c
					break
			else:
				obj = c
				break

		return obj

	def vmware_task_wait(self, task):
		""" wait for vcenter task to finish """

		task_done = False

		while not task_done:
			if task.info.state == 'success':
				#print task
				#print task.info.entity
				return True

			elif task.info.state == 'error':
				#print task.info.error.faultMessage
				#return False
				return False

			## lets not busy wait CPU 100%...
			time.sleep(1)

	################################################################################

#	def vmware_clone_vm(self, template_name, vm_name, os_type, ipaddress, gateway, netmask):

	def vmware_vm_custspec(self, dhcp=True, gateway=None, netmask=None, ipaddr=None, dns_servers="8.8.8.8", dns_domain="localdomain", os_type=None, os_domain="localdomain", timezone=None, hwClockUTC=True, domain_join_user=None, domain_join_pass=None, fullname=None, orgname=None,productid=""):
		"""This function generates a vmware VM customisation spec for use in cloning a VM. 

		   If you choose DHCP (the default) the gateway, netmask, ipaddr, dns_servers and dns_domain parameters are ignored.

		   For Linux use these optional parameters:
		   os_domain - usually soton.ac.uk
		   hwClockUTC - usually True
		   timezone - usually 'Europe/London'

		   For Windows use these optional parameters:
		   timezone - numerical ID, usually 85 for UK.
		   os_domain   - the AD domain to join, usually soton.ac.uk
		   domain_join_user - the user to join AD with
		   domain_join_pass - the user's password
		   fullname - the fullname of the customer
		   orgname - the organisation name of the customer

		"""

		## global IP settings
		globalIPsettings = vim.vm.customization.GlobalIPSettings()

		## these are optional for DHCP
		if not dhcp:
			globalIPsettings.dnsSuffixList = [dns_domain]
			globalIPsettings.dnsServerList  = dns_servers

		## network settings master object
		ipSettings                   = vim.vm.customization.IPSettings()

		## the IP address
		if dhcp:
			ipSettings.ip            = vim.vm.customization.DhcpIpGenerator()
		else:
			fixedIP                  = vim.vm.customization.FixedIp()
			fixedIP.ipAddress        = ipaddr
			ipSettings.ip            = fixedIP
			ipSettings.dnsDomain     = dns_domain
			ipSettings.dnsServerList = dns_servers
			ipSettings.gateway       = [gateway]
			ipSettings.subnetMask    = netmask

		## Create the 'adapter mapping'
		adapterMapping            = vim.vm.customization.AdapterMapping()
		adapterMapping.adapter    = ipSettings

		# create the customisation specification
		custspec                  = vim.vm.customization.Specification()
		custspec.globalIPSettings = globalIPsettings
		custspec.nicSettingMap    = [adapterMapping]

		if os_type == self.OS_TYPE_BY_NAME['Linux']:

			linuxprep            = vim.vm.customization.LinuxPrep()
			linuxprep.domain     = os_domain
			linuxprep.hostName   = vim.vm.customization.VirtualMachineNameGenerator()
			linuxprep.hwClockUTC = hwClockUTC
			linuxprep.timeZone   = timezone

			## finally load in the sysprep into the customisation spec
			custspec.identity = linuxprep
	
		elif os_type == self.OS_TYPE_BY_NAME['Windows']:

			## the windows sysprep /CRI
			guiUnattended = vim.vm.customization.GuiUnattended()
			guiUnattended.autoLogon = False
			guiUnattended.autoLogonCount = 0
			guiUnattended.timeZone = timezone

			sysprepIdentity = vim.vm.customization.Identification()
			sysprepIdentity.domainAdmin = domain_join_user
			sysprepPassword = vim.vm.customization.Password()
			sysprepPassword.plainText = True
			sysprepPassword.value = domain_join_pass
			sysprepIdentity.domainAdminPassword = sysprepPassword
			sysprepIdentity.joinDomain = os_domain

			sysprepUserData = vim.vm.customization.UserData()
			sysprepUserData.computerName = vim.vm.customization.VirtualMachineNameGenerator()
			sysprepUserData.fullName = fullname
			sysprepUserData.orgName = orgname
			sysprepUserData.productId = productid

			sysprep                = vim.vm.customization.Sysprep()
			sysprep.guiUnattended  = guiUnattended
			sysprep.identification = sysprepIdentity
			sysprep.userData       = sysprepUserData

			## finally load in the sysprep into the customisation spec
			custspec.identity = sysprep

		else:
			raise Exception("Invalid os_type")

		return custspec
	

	def vmware_clone_vm(self, vm_template, vm_name, vm_datacenter=None, vm_datastore=None, vm_folder=None, vm_cluster=None, vm_rpool=None, vm_network=None, vm_poweron=False, custspec=None):
		"""This function connects to vcenter and clones a virtual machine. Only vm_template and
		   vm_name are required parameters although this is unlikely what you'd want - please
		   read the parameters and check if you want to use them.

		   If you want to customise the VM after cloning attach a customisation spec via the 
		   custspec optional parameter.

		   TODO: vm_network currently does not work.
		   TODO: exception throwing when objects are not found...

		"""

		## Connect to vCenter
		si = SmartConnect(host=self.config['VMWARE_HOST'], user=self.config['VMWARE_USER'], pwd=self.config['VMWARE_PASS'], port=self.config['VMWARE_PORT'])
		content = si.RetrieveContent()

		## Get the template
		template = self.vmware_get_obj(content, [vim.VirtualMachine], vm_template)

		## VMware datacenter - this is only used to get the folder
		datacenter = self.vmware_get_obj(content, [vim.Datacenter], vm_datacenter)

		## VMware folder
		if vm_folder:
			destfolder = get_obj(content, [vim.Folder], vm_folder)
		else:
			destfolder = datacenter.vmFolder

		## VMware datastore
		datastore = self.vmware_get_obj(content, [vim.Datastore], vm_datastore)

		## VMware Cluster
		cluster = self.vmware_get_obj(content, [vim.ClusterComputeResource], vm_cluster)

		## Resource pool TODO what about multiple "Root Resource Pool"'s ?!?
		rpool = self.vmware_get_obj(content, [vim.ResourcePool], vm_rpool)
		if rpool == None:
			rpool = cluster.resourcePool

		## Create the relocation specification
		relospec = vim.vm.RelocateSpec()
		relospec.datastore = datastore
		relospec.pool = rpool

		## Create the clone spec
		clonespec = vim.vm.CloneSpec()
		clonespec.powerOn  = vm_poweron
		clonespec.location = relospec

		## If the user wants to customise the VM after creation...
		if not custspec == False:
			clonespec.customization = custspec

		return template.Clone(folder=destfolder, name=vm_name, spec=clonespec)

	############################################################################

	def vmware_vmreconfig_cpu(self, vm, cpus, cpus_per_socket, hotadd=True):
		"""Reconfigures the CPU count of a VM and enables/disabled CPU hot-add. 'vm' 
		is a PyVmomi managed object, 'cpus' is the TOTAL number of vCPUs to have, and
		'cpus_per_socket' is the number of cores per socket. The VM will end up having
		(cpus / cpus_per_socket) CPU sockets, each having cpus_per_socket. 'hotadd'
		is a boolean indicating whether or not to enable hot add or not.

		Returns a PyVmomi task object relating to the VMware task."""

		configSpec                   = vim.VirtualMachineConfigSpec()
		configSpec.cpuHotAddEnabled  = hotadd
		configSpec.numCPUs           = cpus
		configSpec.numCoresPerSocket = cpus_per_socket
		return vm.ReconfigVM_Task(configSpec)

	def vmware_vmreconfig_ram(self, vm, megabytes=1024, hotadd=True):
		"""Reconfigures the amount of RAM a VM has, and whether memory can be hot-
		added to the system. 'vm' is a PyVmomi managed object, 'megabytes' is the 
		required amount of RAM in megabytes. 'hotadd' is a boolean indicating whether
		or not to enable hot add or not.

		Returns a PyVmomi task object relating to the VMware task."""

		configSpec                     = vim.VirtualMachineConfigSpec()
		configSpec.memoryHotAddEnabled = hotadd
		configSpec.memoryMB            = megabytes
		return vm.ReconfigVM_Task(configSpec)

	def vmware_vm_add_disk(self, vm, size_in_bytes, thin=True):
		
		# find the last SCSI controller on the VM
		for device in vm.config.hardware.device:
			if isinstance(device, vim.vm.device.VirtualSCSIController):
				controller = device

			if hasattr(device.backing, 'fileName'):
				unit_number = int(device.unitNumber) + 1

				## unit_number 7 reserved scsi controller (cos of historical legacy stuff when LUN numbers were 0 to 7 and 7 was the highest priority hence the controller)
				if unit_number == 7:
					unit_number = 8

				## can't have more than 16 disks
				if unit_number >= 16:
					raise Exception("Too many disks on the SCSI controller")				

		if controller == None:
			raise Exception("No scsi controller found!")

		if unit_number == None:
			raise Exception("Unable to calculate logical unit number for SCSI device")

		newdev = vim.vm.device.VirtualDeviceSpec()		
		newdev.fileOperation = "create"
		newdev.operation = "add"
		newdev.device = vim.vm.device.VirtualDisk()

		newdev.device.backing = vim.vm.device.VirtualDisk.FlatVer2BackingInfo()
		newdev.device.backing.diskMode = 'persistent'
		if thin:
			newdev.device.backing.thinProvisioned = True


		newdev.device.capacityInBytes = size_in_bytes
		newdev.device.capacityInKB = size_in_bytes * 1024
		newdev.device.controllerKey = controller.key
		newdev.device.unitNumber = unit_number

		devices = []
		devices.append(newdev)

		configSpec = vim.vm.ConfigSpec()
		configSpec.deviceChange = devices
		return vm.ReconfigVM_Task(spec=configSpec)

	def vmware_vm_poweron(self, vm):
		"""Powers on a virtual machine."""

		return vm.PowerOn()

	## --> THIS IS CURRENTLY UNTESTED!!! <--
	def servicenow_create_ci(self, ci_name, os_type, os_name, cpus, ram_mb, disk_gb, ipaddr, virtual=True):
		"""Creates a new CI within ServiceNow.
		     - ci_name: The name of the CI, e.g. srv01234
		     - os_type: The OS type as a number, see OS_TYPE_BY_NAME
		     - os_name: The name of the OS, as used by ServiceNow
		     - cpus: The total number of CPUs the CI has
		     - ram_mb: The amount of RAM of the CI in MeB
		     - disk_gb: The total amount of disk space in GiB
		     - ipaddr: The IP address of the CI
		     - virtual: Boolean indicating if the CI is a VM (True) or Physical (False). Defaults to True.

		On success, returns the sys_id of the object created in ServiceNow.
		"""

		# Decide which ServiceNow table we need to put the CI in to, based on the OS
		if os_type == self.OS_TYPE_BY_NAME['Linux']:
			table_name = "cmdb_ci_linux_server"
		elif os_type == self.OS_TYPE_BY_NAME['Windows']:
			table_name = "cmdb_ci_windows_server"
		else:
			raise Exception('Unknown os_type passed to servicenow_create_ci')

		# Build the data for the CI
		vm_data = { 'name': str(ci_name), 'os': str(os_name), 'cpu_count': str(cpus), 'disk_space': str(disk_gb), 'virtual': str(virtual).lower(), 'ip_address': ipaddr, 'ram': str(ram_mb) }

		# json= was only added in Requests 2.4.2, so might need to be data=json.dumps(vm_data)
		# Content-Type header may be superfluous as Requests might add it anyway, due to json=
		r = requests.post('https://' + self.config['SN_HOST'] + '/api/now/v1/table/' + table_name + '/', auth=(self.config['SN_USER'], self.config['SN_PASS']), headers={'Accept': 'application/json', 'Content-Type': 'application/json'}, json=vm_data)

		# Parse the response
		if r is not None:
			# Parse the JSON and return the sys_id that ServiceNow gives us
			response_json = r.json()
			return response_json['sys_id']
		else:
			raise Exception('Failed to create ServiceNow object. API Request failed')

		## puppet stuff?
		## let users logon??
		## windows ou?
		## machineid

class TaskHelper(object):

	def __init__(self, config, workflow_name, task_id, username):
		self.config        = config
		self.workflow_name = workflow_name
		self.task_id       = task_id
		self.username      = username
		self.event_id      = -1

		self.db   = mysql.connect(self.config['MYSQL_HOST'],self.config['MYSQL_USER'],self.config['MYSQL_PASS'],self.config['MYSQL_NAME'])
		self.curd = self.db.cursor(mysql.cursors.DictCursor)
		self.lib  = NeoCortexLib(self.db, self.config)

	def run(self, task_module, options):

		try:
			task_module.run(self, options)
			self._end_task(True)
		except Exception as ex:
			self._log_exception(ex)
			self._end_task(False)

	def _log_exception(self, ex):
		exception_type = str(type(ex).__name__)
		exception_message = str(ex)
		self.curd.execute("INSERT INTO `events` (`source`, `related_id`, `name`, `username`, `desc`, `status`, `start`, `end`) VALUES (%s, %s, %s, %s, %s, 2, NOW(), NOW())", 
			('neocortex.task',self.task_id, self.workflow_name + "." + 'exception', self.username, "An exception occured during task execution: " + exception_type + " - " + exception_message))
		self.db.commit()

	def event(self, name, description, success=True):
		# Handle closing an existing event if there is still one
		if self.event_id != -1:
			self.end_event(success)

		name = self.workflow_name + "." + name
		self.curd.execute("INSERT INTO `events` (`source`, `related_id`, `name`, `username`, `desc`, `start`) VALUES (%s, %s, %s, %s, %s, NOW())", ('neocortex.task', self.task_id, name, self.username, description))
		self.db.commit()
		self.event_id = self.curd.lastrowid
		return True

	def update_event(self, description):
		if self.event_id == -1:
			return False

		self.curd.execute("UPDATE `events` SET `desc` = %s WHERE `id` = %s", (description, self.event_id))
		self.db.commit()

		return True

	def end_event(self, success=True, description=None):
		if self.event_id == -1:
			return False

		if not description == None:
			self.update_event(description)

		if success:
			status = 1
		else:
			status = 2 

		self.curd.execute("UPDATE `events` SET `status` = %s WHERE `id` = %s", (status, self.event_id))
		self.db.commit()
		self.event_id = -1

		return True

	def _end_task(self, success=True):
		# Handle closing an existing event if there is still one
		if self.event_id != -1:
			self.end_event(success)

		if success:
			status = 1
		else:
			status = 2 

		self.curd.execute("UPDATE `tasks` SET `status` = %s, `end` = NOW() WHERE `id` = %s", (status, self.task_id))
		self.db.commit()

class NeoCortex(object):

	debug = False
	db    = None

	## PRIVATE METHODS #########################################################

	def __init__(self):
		syslog.openlog("neocortex", syslog.LOG_PID)
		syslog.syslog('Attempting to start neocortex')

		## Load the config and drop privs
		self._load_config(CONFIG_FILE)
		self._drop_privs()

	def _get_cursor(self):
		self._get_db()
		return self.db.cursor(mysql.cursors.DictCursor)

	def _get_db(self):
		if self.db:
			if self.db.open:
				try:
					curd = self.db.cursor(mysql.cursors.DictCursor)
					curd.execute('SELECT 1')
					result = curd.fetchone();

					if result:
						return self.db

				except (AttributeError, mysql.OperationalError):
					syslog.syslog("MySQL connection is closed, will attempt reconnect")

		## If we didn't return up above then we need to connect first
		return self._db_connect()
		
	def _db_connect(self):
		syslog.syslog("Attempting connection to MySQL")
		self.db = mysql.connect(self.config['MYSQL_HOST'], self.config['MYSQL_USER'], self.config['MYSQL_PASS'], self.config['MYSQL_NAME'])
		curd = self.db.cursor(mysql.cursors.DictCursor)
		curd.execute("SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED")
		syslog.syslog("Connection to MySQL established")
		return self.db

	def _load_config(self, filename): 
		d = imp.new_module('config')
		d.__file__ = filename
		try:
			with open(filename) as config_file:
				exec(compile(config_file.read(), filename, 'exec'), d.__dict__)
		except IOError as e:
			syslog.syslog('Unable to load configuration file (%s)' % e.strerror)
			sys.exit(1)
		self.config = {}
		for key in dir(d):
			if key.isupper():
				self.config[key] = getattr(d, key)

		## ensure we have required config options
		for wkey in ['NEOCORTEX_SET_GID', 'NEOCORTEX_SET_UID', 'NEOCORTEX_KEY', 'WORKFLOWS_DIR']:
			if not wkey in self.config.keys():
				print "Missing configuation option: " + wkey
				sys.exit(1)

		if 'DEBUG' in self.config.keys():
			if self.config['DEBUG'] == True:
				self.debug = True
				
		return True

	def _drop_privs(self):
		## Drop privileges, looking up the UID/GID if not given numerically
		if str(self.config['NEOCORTEX_SET_GID']).isdigit():
			os.setgid(self.config['NEOCORTEX_SET_GID'])
		else:
			import grp
			os.setgid(grp.getgrnam(self.config['NEOCORTEX_SET_GID']).gr_gid)

		if str(self.config['NEOCORTEX_SET_UID']).isdigit():
			os.setuid(self.config['NEOCORTEX_SET_UID'])
		else:
			import pwd
			os.setuid(pwd.getpwnam(self.config['NEOCORTEX_SET_UID']).pw_uid)

	def _record_task(self, module_name, username):
		curd = self._get_cursor()
		curd.execute("INSERT INTO `tasks` (module, username, start) VALUES (%s, %s, NOW())", (module_name, username))
		self.db.commit()
		return curd.lastrowid

	## PUBLIC METHODS ##########################################################

	def ping(self):
		return True

	#### this function is used to submit jobs/tasks.
	## method - the method to call within this system
	## username - who submitted this task
	## options - a dictionary of arguments for the method.
	def create_task(self, workflow_name, username, options):

		if not os.path.isdir(self.config['WORKFLOWS_DIR']):
			raise IOError("The config option WORKFLOWS_DIR is not a directory")

		fqp = os.path.join(self.config['WORKFLOWS_DIR'], workflow_name)

		if not os.path.exists(fqp):
			raise IOError("The workflow directory was not found")

		if not os.path.isdir(fqp):
			raise IOError("The workflow name was not a directory")

		task_file = os.path.join(fqp,"task.py")
		try:
			task_module = imp.load_source(workflow_name, task_file)
		except Exception as ex:
			raise ImportError("Could not load workflow from file " + task_file + ": " + str(ex))

		task_id      = self._record_task(workflow_name, username)
		task_helper  = TaskHelper(self.config, workflow_name, task_id, username)
		task         = Process(target=task_helper.run, args=(task_module, options))
		task.start()

		return task_id

	## This function allows the Flask web app to allocate names (as well as tasks)
	def allocate_name(self, class_name, system_comment, username, num):
		lib = NeoCortexLib(self._get_db(), self.config)
		return lib.allocate_name(class_name, system_comment, username, num)

	## TODO add allocate_infoblox function too?

################################################################################

def signal_handler_term(signal, frame):
	signal_handler('SIGTERM')
	
################################################################################
	
def signal_handler_int(signal, frame):
	signal_handler('SIGINT')
	
################################################################################
		
def signal_handler(signal):
	global pyro_daemon
	syslog.syslog('Caught signal ' + str(signal) + ' - exiting')
	Pyro4.core.Daemon.shutdown(pyro_daemon)
	sys.exit(0)

################################################################################
	
if __name__ == "__main__":
	d = NeoCortex()
	
	signal.signal(signal.SIGTERM, signal_handler_term)
	signal.signal(signal.SIGINT, signal_handler_int)
	pyro_daemon = Pyro4.Daemon(host='localhost',port=1888)
	pyro_daemon._pyroHmacKey = d.config['NEOCORTEX_KEY']
	uri         = pyro_daemon.register(d,'neocortex')
	syslog.syslog('neocortex started')
	pyro_daemon.requestLoop()
		
