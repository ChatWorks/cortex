#!/usr/bin/python

import Pyro4
import syslog
import signal
import os
import imp
from multiprocessing import Process, Value
import MySQLdb as mysql
import sys
import requests
import json
import time

## for vmware
from pyVmomi import vim
from pyVim.connect import SmartConnect, Disconnect

CONFIG_FILE = '/data/cortex/cortex.conf'
Pyro4.config.SERVERTYPE = "multiplex"
Pyro4.config.SOCK_REUSE = True

class NotFoundError(Exception):
	"""Exception to represent a condition where something asked for is not found"""

class DisabledError(Exception):
	"""Exception to represent a condition where something has been disabled"""

class InfobloxError(Exception):
	"""Exception to represent a fault when interacting with Infoblox"""

class NeoCortexLib(object):
	"""Library functions used in both neocortex itself and the neocortex tasks, hence a seperate object"""

	OS_TYPE_BY_ID   = {0: "None", 1: "Linux", 2: "Windows" }
	OS_TYPE_BY_NAME = {"None": 0, "Linux": 1, "Windows": 2}
	SYSTEM_TYPE_BY_ID = {0: "System", 1: "Legacy", 2: "Other"}
	SYSTEM_TYPE_BY_NAME = {"System": 0, "Legacy": 1, "Other": 2}

	def __init__(self, db, config):
		self.db = db
		self.config = config

	################################################################################

	def allocate_name(self, class_name, comment, username, num=1):
		"""Allocates 'num' systems, of type 'class_name' each with the given
		comment. Returns a dictionary with mappings between each new name
		and the corresponding row ID in the database table."""

		# dictionary of new systems
		new_systems = {}

		# Get a cursor to the database
		cur = self.db.cursor(mysql.cursors.DictCursor)

		# The following MySQL code is a bit complicated but as an explanation:
		#  * The classes table contains the number of the next system in each
		#    class to allocate.
		#  * To prevent race conditions when allocating (and thus so two
		#    systems don't get allocated with the same number) we lock the 
		#    tables we want to view/modify during this function.
		#  * This prevents other simultanteously running calls to this function
		#    from allocating a name temporarily (the call to LOCK TABLE will
		#    block/hang until the tables become unlocked again).
		#  * Once a lock is aquired, we get the next number to allocate from
		#    the classes table, update that table with the next new number,
		#    based on how many names we're simultaneously allocating, and then
		#    create the systems in the systems table.
		#  * This is all commited as one transaction so either this all happens
		#    or none of it happens (i.e. in case of an error)
		#  * In all scenarios, we end by unlocking the table so other calls to
		#    this function can carry on.

		## 1. Lock the table to prevent other requests issuing names whilst we are
		cur.execute('LOCK TABLE `classes` WRITE, `systems` WRITE; ')

		# 2a. Get the class (along with the next nubmer to allocate)
		try:
			cur.execute("SELECT * FROM `classes` WHERE `name` = %s",(class_name))
			class_data = cur.fetchone()
		except Exception as ex:
			cur.execute('UNLOCK TABLES;')
			raise NotFoundError

		# 2b. Ensure the class was found and that it is not disabled
		if class_data == None:
			cur.execute('UNLOCK TABLES;')
			raise NotFoundError
		elif int(class_data['disabled']) == 1:
			cur.execute('UNLOCK TABLES;')
			raise DisabledError

		try:
			## 3. Increment the number by the number we're simultaneously allocating
			cur.execute("UPDATE `classes` SET `lastid` = %s WHERE `name` = %s", (int(class_data['lastid']) + int(num), class_name))

			## 4. Create the appropriate number of servers
			for i in xrange(1, num+1):
				new_number = int(class_data['lastid']) + i
				new_name   = self.pad_system_name(class_name, new_number, class_data['digits'])

				cur.execute("INSERT INTO `systems` (`type`, `class`, `number`, `name`, `allocation_date`, `allocation_who`, `allocation_comment`) VALUES (%s, %s, %s, %s, NOW(), %s, %s)",
					(self.SYSTEM_TYPE_BY_NAME['System'], class_name, new_number, new_name, username, comment))

				# store a record of the new system so we can give this back to the browser in a minute
				new_systems[new_name] = cur.lastrowid

			## 5. All names are now created and the table incremented. Time to commit.
			self.db.commit()
		except Exception as ex:
			cur.execute('UNLOCK TABLES;')
			raise ex

		## 6. Finally, unlock the tables so others can allocate
		cur.execute('UNLOCK TABLES;')

		return new_systems

	################################################################################

	def pad_system_name(self, prefix, number, digits):
		"""Takes a class name ('prefix') a system number, and the number of
		digits that class should have in its name and formats a string to that
		specification. For example, if prefix is 'test', number is '12' and
		'digits' is 5, then this returns 'test00012'"""

		return ("%s%0" + str(int(digits)) + "d") % (prefix, number)	

	################################################################################

	def infoblox_create_host(self, name, subnet):
		payload = {'name': name, "ipv4addrs": [{"ipv4addr":"func:nextavailableip:" + subnet}],}
		r = requests.post("https://" + self.config['INFOBLOX_HOST'] + "/wapi/v2.0/record:host", data=json.dumps(payload), auth=(self.config['INFOBLOX_USER'], self.config['INFOBLOX_PASS']))

		if r.status_code == 201:
			objectid = str(r.json())
			r = requests.get("https://" + self.config['INFOBLOX_HOST'] + "/wapi/v2.0/" + objectid, auth=(self.config['INFOBLOX_USER'], self.config['INFOBLOX_PASS']))
	
			if r.status_code == 200:
				response = r.json()

				try:
					return response['ipv4addrs'][0]['ipv4addr']
				except Exception as ex:
					raise InfobloxError("Malformed JSON response from Infoblox API")
			else:
				raise InfobloxError("Error returned from Infoblox API. Code " + str(r.status_code) + ": " + r.text)
		else:
			raise InfobloxError("Error returned from Infoblox API. Code " + str(r.status_code) + ": " + r.text)

	def vmware_get_obj(self, content, vimtype, name):
		"""
		Return an object by name, if name is None the
		first found object is returned
		"""
		obj = None
		container = content.viewManager.CreateContainerView(
		content.rootFolder, vimtype, True)
		for c in container.view:
			if name:
				if c.name == name:
					obj = c
					break
			else:
				obj = c
				break

		return obj

	def vmware_task_wait(self, task):
		""" wait for vcenter task to finish """

		task_done = False

		while not task_done:
			if task.info.state == 'success':
				return True

			elif task.info.state == 'error':
				return False

			## lets not busy wait CPU 100%...
			time.sleep(1)

	################################################################################

	def vmware_clone_vm(self, template_name, vm_name, os_type, ipaddress, gateway, netmask):
		si = SmartConnect(host=self.config['VMWARE_HOST'], user=self.config['VMWARE_USER'], pwd=self.config['VMWARE_PASS'], port=self.config['VMWARE_PORT'])
		content = si.RetrieveContent()
		template = self.vmware_get_obj(content, [vim.VirtualMachine], template_name)

		datacenter = self.vmware_get_obj(content, [vim.Datacenter], None)
		datastore  = self.vmware_get_obj(content, [vim.Datastore], None)
		cluster    = self.vmware_get_obj(content, [vim.ClusterComputeResource], None)

		rpool      = self.vmware_get_obj(content, [vim.ResourcePool], 'Root Resource Pool')
		destfolder = datacenter.vmFolder

		if rpool == None:
			rpool = cluster.resourcePool
	
		relospec = vim.vm.RelocateSpec()
		relospec.datastore = datastore
		relospec.pool = rpool
 
		## global IP settings
		globalIPsettings = vim.vm.customization.GlobalIPSettings()
		globalIPsettings.dnsSuffixList = ['soton.ac.uk']
		globalIPsettings.dnsServerList  = ['152.78.110.110','152.78.111.81', '152.78.111.113']

		## the IP address
		ipAddr = vim.vm.customization.FixedIp()
		ipAddr.ipAddress = ipaddress

		## network settings
		ipSettings = vim.vm.customization.IPSettings()
		ipSettings.dnsDomain = "soton.ac.uk"
		ipSettings.dnsServerList = ['152.78.110.110','152.78.111.81', '152.78.111.113']
		ipSettings.gateway = [gateway]
		ipSettings.ip = ipAddr
		ipSettings.subnetMask = netmask
		adapterMapping = vim.vm.customization.AdapterMapping()
		adapterMapping.adapter = ipSettings

		# the customisation specification
		custspec = vim.vm.customization.Specification()
		custspec.globalIPSettings = globalIPsettings
		custspec.nicSettingMap = [adapterMapping]

		if os_type == self.OS_TYPE_BY_NAME['Linux']:
			linuxprep = vim.vm.customization.LinuxPrep()
			linuxprep.domain = "soton.ac.uk"
			linuxprep.hostName = vim.vm.customization.VirtualMachineNameGenerator()
			linuxprep.hwClockUTC = True
			linuxprep.timeZone = "Europe/London"

			## finally load in the sysprep into the customisation spec
			custspec.identity = linuxprep
		
		if os_type == self.OS_TYPE_BY_NAME['Windows']:

			## the windows sysprep /CRI
			guiUnattended = vim.vm.customization.GuiUnattended()
			guiUnattended.autoLogon = False
			guiUnattended.autoLogonCount = 0
			guiUnattended.timeZone = 85

			sysprepIdentity = vim.vm.customization.Identification()
			sysprepIdentity.domainAdmin = ""
			sysprepPassword = vim.vm.customization.Password()
			sysprepPassword.plainText = True
			sysprepPassword.value = ""
			sysprepIdentity.domainAdminPassword = sysprepPassword
			sysprepIdentity.joinDomain = "devdomain.soton.ac.uk"

			sysprepUserData = vim.vm.customization.UserData()
			sysprepUserData.computerName = vim.vm.customization.VirtualMachineNameGenerator()
			sysprepUserData.fullName = "University of Southampton"
			sysprepUserData.orgName = "University of Southampton"
			sysprepUserData.productId = ""

			sysprep                = vim.vm.customization.Sysprep()
			sysprep.guiUnattended  = guiUnattended
			sysprep.identification = sysprepIdentity
			sysprep.userData       = sysprepUserData

			## finally load in the sysprep into the customisation spec
			custspec.identity = sysprep

		## Create the clone spec!
		clonespec = vim.vm.CloneSpec()
		clonespec.location = relospec
		clonespec.customization = custspec
		clonespec.powerOn = False

		return template.Clone(folder=destfolder, name=vm_name, spec=clonespec)

		## reconfig to cpu/ram/disk.
		
		## put machine ID in.

		## create service now object.

		## power it on 

		## puppet stuff?

		## let users logon??

		## puppet environment group?!

		## windows ou?


class TaskHelper(object):

	def __init__(self, config, workflow_name, task_id, username):
		self.config        = config
		self.workflow_name = workflow_name
		self.task_id       = task_id
		self.username      = username
		self.event_id      = -1

		self.db   = mysql.connect(self.config['MYSQL_HOST'],self.config['MYSQL_USER'],self.config['MYSQL_PASS'],self.config['MYSQL_NAME'])
		self.curd = self.db.cursor(mysql.cursors.DictCursor)
		self.lib  = NeoCortexLib(self.db, self.config)

	def run(self, task_module, options):

		try:
			task_module.run(self, options)
			self._end_task(True)
		except Exception as ex:
			self._log_exception(ex)
			self._end_task(False)

	def _log_exception(self, ex):
		exception_type = str(type(ex).__name__)
		exception_message = str(ex)
		self.curd.execute("INSERT INTO `events` (`source`, `related_id`, `name`, `username`, `desc`, `status`, `start`, `end`) VALUES (%s, %s, %s, %s, %s, 2, NOW(), NOW())", 
			('neocortex.task',self.task_id, self.workflow_name + "." + 'exception', self.username, "An exception occured during task execution: " + exception_type + " - " + exception_message))
		self.db.commit()

	def event(self, name, description, success=True):
		# Handle closing an existing event if there is still one
		if self.event_id != -1:
			self.end_event(success)

		name = self.workflow_name + "." + name
		self.curd.execute("INSERT INTO `events` (`source`, `related_id`, `name`, `username`, `desc`, `start`) VALUES (%s, %s, %s, %s, %s, NOW())", ('neocortex.task', self.task_id, name, self.username, description))
		self.db.commit()
		self.event_id = self.curd.lastrowid
		return True

	def update_event(self, description):
		if self.event_id == -1:
			return False

		self.curd.execute("UPDATE `events` SET `desc` = %s WHERE `id` = %s", (description, self.event_id))
		self.db.commit()

		return True

	def end_event(self, success=True, description=None):
		if self.event_id == -1:
			return False

		if not description == None:
			self.update_event(description)

		if success:
			status = 1
		else:
			status = 2 

		self.curd.execute("UPDATE `events` SET `status` = %s WHERE `id` = %s", (status, self.event_id))
		self.db.commit()
		self.event_id = -1

		return True

	def _end_task(self, success=True):
		# Handle closing an existing event if there is still one
		if self.event_id != -1:
			self.end_event(success)

		if success:
			status = 1
		else:
			status = 2 

		self.curd.execute("UPDATE `tasks` SET `status` = %s, `end` = NOW() WHERE `id` = %s", (status, self.task_id))
		self.db.commit()

class NeoCortex(object):

	debug = False
	db    = None

	## PRIVATE METHODS #########################################################

	def __init__(self):
		syslog.openlog("neocortex", syslog.LOG_PID)
		syslog.syslog('Attempting to start neocortex')

		## Load the config and drop privs
		self._load_config(CONFIG_FILE)
		self._drop_privs()

	def _get_cursor(self):
		self._get_db()
		return self.db.cursor(mysql.cursors.DictCursor)

	def _get_db(self):
		if self.db:
			if self.db.open:
				try:
					curd = self.db.cursor(mysql.cursors.DictCursor)
					curd.execute('SELECT 1')
					result = curd.fetchone();

					if result:
						return self.db

				except (AttributeError, mysql.OperationalError):
					syslog.syslog("MySQL connection is closed, will attempt reconnect")

		## If we didn't return up above then we need to connect first
		return self._db_connect()
		
	def _db_connect(self):
		syslog.syslog("Attempting connection to MySQL")
		self.db = mysql.connect(self.config['MYSQL_HOST'], self.config['MYSQL_USER'], self.config['MYSQL_PASS'], self.config['MYSQL_NAME'])
		curd = self.db.cursor(mysql.cursors.DictCursor)
		curd.execute("SET SESSION TRANSACTION ISOLATION LEVEL READ COMMITTED")
		syslog.syslog("Connection to MySQL established")
		return self.db

	def _load_config(self, filename): 
		d = imp.new_module('config')
		d.__file__ = filename
		try:
			with open(filename) as config_file:
				exec(compile(config_file.read(), filename, 'exec'), d.__dict__)
		except IOError as e:
			syslog.syslog('Unable to load configuration file (%s)' % e.strerror)
			sys.exit(1)
		self.config = {}
		for key in dir(d):
			if key.isupper():
				self.config[key] = getattr(d, key)

		## ensure we have required config options
		for wkey in ['NEOCORTEX_SET_GID', 'NEOCORTEX_SET_UID', 'NEOCORTEX_KEY', 'WORKFLOWS_DIR']:
			if not wkey in self.config.keys():
				print "Missing configuation option: " + wkey
				sys.exit(1)

		if 'DEBUG' in self.config.keys():
			if self.config['DEBUG'] == True:
				self.debug = True
				
		return True

	def _drop_privs(self):
		## Drop privileges, looking up the UID/GID if not given numerically
		if str(self.config['NEOCORTEX_SET_GID']).isdigit():
			os.setgid(self.config['NEOCORTEX_SET_GID'])
		else:
			import grp
			os.setgid(grp.getgrnam(self.config['NEOCORTEX_SET_GID']).gr_gid)

		if str(self.config['NEOCORTEX_SET_UID']).isdigit():
			os.setuid(self.config['NEOCORTEX_SET_UID'])
		else:
			import pwd
			os.setuid(pwd.getpwnam(self.config['NEOCORTEX_SET_UID']).pw_uid)

	def _record_task(self, module_name, username):
		curd = self._get_cursor()
		curd.execute("INSERT INTO `tasks` (module, username, start) VALUES (%s, %s, NOW())", (module_name, username))
		self.db.commit()
		return curd.lastrowid

	## PUBLIC METHODS ##########################################################

	def ping(self):
		return True

	#### this function is used to submit jobs/tasks.
	## method - the method to call within this system
	## username - who submitted this task
	## options - a dictionary of arguments for the method.
	def create_task(self, workflow_name, username, options):

		if not os.path.isdir(self.config['WORKFLOWS_DIR']):
			raise IOError("The config option WORKFLOWS_DIR is not a directory")

		fqp = os.path.join(self.config['WORKFLOWS_DIR'], workflow_name)

		if not os.path.exists(fqp):
			raise IOError("The workflow directory was not found")

		if not os.path.isdir(fqp):
			raise IOError("The workflow name was not a directory")

		task_file = os.path.join(fqp,"task.py")
		try:
			task_module = imp.load_source(workflow_name, task_file)
		except Exception as ex:
			raise ImportError("Could not load workflow from file " + task_file + ": " + str(ex))

		task_id      = self._record_task(workflow_name, username)
		task_helper  = TaskHelper(self.config, workflow_name, task_id, username)
		task         = Process(target=task_helper.run, args=(task_module, options))
		task.start()

		return task_id

	## This function allows the Flask web app to allocate names (as well as tasks)
	def allocate_name(self, class_name, system_comment, username, num):
		lib = NeoCortexLib(self._get_db(), self.config)
		return lib.allocate_name(class_name, system_comment, username, num)

	## TODO add allocate_infoblox function too

################################################################################

def signal_handler_term(signal, frame):
	signal_handler('SIGTERM')
	
################################################################################
	
def signal_handler_int(signal, frame):
	signal_handler('SIGINT')
	
################################################################################
		
def signal_handler(signal):
	global pyro_daemon
	syslog.syslog('Caught signal ' + str(signal) + ' - exiting')
	Pyro4.core.Daemon.shutdown(pyro_daemon)
	sys.exit(0)

################################################################################
	
if __name__ == "__main__":
	d = NeoCortex()
	
	signal.signal(signal.SIGTERM, signal_handler_term)
	signal.signal(signal.SIGINT, signal_handler_int)
	pyro_daemon = Pyro4.Daemon(host='localhost',port=1888)
	pyro_daemon._pyroHmacKey = d.config['NEOCORTEX_KEY']
	uri         = pyro_daemon.register(d,'neocortex')
	syslog.syslog('neocortex started')
	pyro_daemon.requestLoop()
		
